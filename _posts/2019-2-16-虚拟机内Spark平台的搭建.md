---
layout: article
title: 虚拟机内Spark平台的搭建
key: 100003
category: tools
tags: tools
date: 2019-02-16 19:00:00 +08:00
modify_date: 2019-02-18 14:40:00 +08:00
---

由于要测试一个多序列比对软件的Spark版本，PastaSpark，所以想着自己来搭建一个
spark集群来测试这个软件能不能用。

<!--more-->

[参考博客Linux上安装Hadoop集群(CentOS7+hadoop-2.8.0)](https://blog.csdn.net/pucao_cug/article/details/71698903)

# 准备工作

下载Centos镜像，这里Centos7有DVD、Everything、Minimal等版本，如果是准备在实体机上搭建，可以选择Everything版本。[Centos7 64位镜像](http://mirrors.aliyun.com/centos/7/isos/x86_64/)

Minimal版本包括东西太少，这里我们选择DVD版本就好。(应需而异)

Hadoop的安装包，因为教程里用的版本是2.8的，这里我下载的也是2.8.5的Hadoop安装包[Hadoop2.8.5下载地址](https://www.apache.org/dyn/closer.cgi/hadoop/common/hadoop-2.8.5/hadoop-2.8.5.tar.gz)

Spark安装包，同上[Spark-2.2.3-bin-hadoop2.7](https://www.apache.org/dyn/closer.lua/spark/spark-2.2.3/spark-2.2.3-bin-hadoop2.7.tgz)

Java安装包，注意需要JDK 8[JDK1.8.0-201](https://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html)

## Linux系统安装

我们在VMware上安装三个CentOs为例，VMware安装这里不细讲，这里有几个点需要注意。

1. SoftWare Selection里边不要选择Minimal install，这里我根据博客里选择的是Infrastructure Server,DNS Name Server,E-mail Server.建议新手选择带图形界面的版本。

2. Network & Host Name勾选

3. 在安装时，可以设置Root密码和建立User。这里我为了方便只使用Root。

### 实现机器间互连

首先使用ifconfig查看三台机器的ip地址，我这里三台IP地址分别是
192.168.80.130
192.168.80.131
192.168.80.132

同时把三台机器的名称改为server1 server2 server3，使用hostname命令修改。然后在
三台机器上分别修改/etc/hosts文件，改为

```
192.168.80.130   server1
192.168.80.131   server2
192.168.80.132   server3
```

改好之后在每台机器上看是否能ping通其他机器。以server1为例

```
ping -c 3 server2
ping -c 3 server3
```

测试成功后在每台机器上执行

```
ssh-keygen -t rsa -P ''
```

执行之后在你用户文件夹下会多出一个.ssh文件夹，里面会有一个叫id_rsa.pub的文件，这是我们所需要的公钥。

我们把三台机器上的公钥复制到一起并保存为一个叫authorized_keys的文件，然后把这个文件发送到每个系统的.ssh文件夹内。

使用ssh登陆其他机器，以server1为例
```
ssh server2
ssh server3
```

注意：在ssh登陆后要使用exit命令退出，不然所做的所有操作都是作用在另外一台机器上

## Spark所需前置软件的安装

### 安装JAVA

[Linux上安装JAVA](https://blog.csdn.net/pucao_cug/article/details/68948639)

### 安装Hadoop

#### 解压缩

假设Hadoop的文件夹在/opt处

#### 新建目录

在/root目录下新建几个目录，复制粘贴执行下面的命令：

```
mkdir  /root/hadoop
mkdir  /root/hadoop/tmp
mkdir  /root/hadoop/var
mkdir  /root/hadoop/dfs
mkdir  /root/hadoop/dfs/name
mkdir  /root/hadoop/dfs/data
```

#### 修改core-site.xml

修改/opt/hadoop/hadoop-2.8.0/etc/hadoop/core-site.xml文件
在<configuration>节点加入配置:

```
 <property>

        <name>hadoop.tmp.dir</name>

        <value>/root/hadoop/tmp</value>

        <description>Abase for other temporary directories.</description>

   </property>

   <property>

        <name>fs.default.name</name>

        <value>hdfs://hserver1:9000</value>

   </property>

</configuration>
```

#### 修改hadoop-env.sh

 修改/opt/hadoop/hadoop-2.8.0/etc/hadoop/hadoop-env.sh文件

将export   JAVA_HOME=${JAVA_HOME}修改为：

```
export JAVA_HOME=/opt/java/jdk1.8.0_121
```

#### 修改hdfs-site.xml

修改/opt/hadoop/hadoop-2.8.0/etc/hadoop/hdfs-site.xml文件在<configuration>节点内加入配置:

```
<property>

   <name>dfs.name.dir</name>

   <value>/root/hadoop/dfs/name</value>

   <description>Path on the local filesystem where theNameNode stores the namespace and transactions logs persistently.</description>

</property>

<property>

   <name>dfs.data.dir</name>

   <value>/root/hadoop/dfs/data</value>

   <description>Comma separated list of paths on the localfilesystem of a DataNode where it should store its blocks.</description>

</property>

<property>

   <name>dfs.replication</name>

   <value>2</value>

</property>

<property>

      <name>dfs.permissions</name>

      <value>false</value>

      <description>need not permissions</description>

</property>
```

#### 新建并修改mapred-site.xml

在该版本中，有一个名为mapred-site.xml.template的文件，复制该文件，然后改名为mapred-site.xml，命令是：

```
cp   /opt/hadoop/hadoop-2.8.0/etc/hadoop/mapred-site.xml.template     /opt/hadoop/hadoop-2.8.0/etc/hadoop/mapred-site.xml
```

修改这个新建的mapred-site.xml文件，在<configuration>节点内加入配置:

```
 <property>

   <name>mapred.job.tracker</name>

   <value>hserver1:49001</value>

</property>

<property>

      <name>mapred.local.dir</name>

       <value>/root/hadoop/var</value>

</property>

<property>

       <name>mapreduce.framework.name</name>

       <value>yarn</value>

</property>
```

#### 修改slaves文件

修改/opt/hadoop/hadoop-2.8.0/etc/hadoop/slaves文件，将里面的localhost删除，添加如下内容：

```
hserver2
hserver3
```

#### 修改yarn-site.xml
3.2.3.6 修改yarn-site.xml文件
修改/opt/hadoop/hadoop-2.8.0/etc/hadoop/yarn-site.xml文件，
在<configuration>节点内加入配置(注意了，内存根据机器配置越大越好，最少也得1.5G不然连example都跑不起来):
```
<property>

        <name>yarn.resourcemanager.hostname</name>

        <value>hserver1</value>

   </property>

   <property>

        <description>The address of the applications manager interface in the RM.</description>

        <name>yarn.resourcemanager.address</name>

        <value>${yarn.resourcemanager.hostname}:8032</value>

   </property>

   <property>

        <description>The address of the scheduler interface.</description>

        <name>yarn.resourcemanager.scheduler.address</name>

        <value>${yarn.resourcemanager.hostname}:8030</value>

   </property>

   <property>

        <description>The http address of the RM web application.</description>

        <name>yarn.resourcemanager.webapp.address</name>

        <value>${yarn.resourcemanager.hostname}:8088</value>

   </property>

   <property>

        <description>The https adddress of the RM web application.</description>

        <name>yarn.resourcemanager.webapp.https.address</name>

        <value>${yarn.resourcemanager.hostname}:8090</value>

   </property>

   <property>

        <name>yarn.resourcemanager.resource-tracker.address</name>

        <value>${yarn.resourcemanager.hostname}:8031</value>

   </property>

   <property>

        <description>The address of the RM admin interface.</description>

        <name>yarn.resourcemanager.admin.address</name>

        <value>${yarn.resourcemanager.hostname}:8033</value>

   </property>

   <property>

        <name>yarn.nodemanager.aux-services</name>

        <value>mapreduce_shuffle</value>

   </property>

   <property>

        <name>yarn.scheduler.maximum-allocation-mb</name>

        <value>2048</value>

        <discription>每个节点可用内存,单位MB,默认8182MB</discription>

   </property>

   <property>

        <name>yarn.nodemanager.vmem-pmem-ratio</name>

        <value>2.1</value>

   </property>

   <property>

        <name>yarn.nodemanager.resource.memory-mb</name>

        <value>2048</value>

</property>

   <property>

        <name>yarn.nodemanager.vmem-check-enabled</name>

        <value>false</value>

</property>
```

### 安装Spark

前提要安装scala，这里不多赘述。

具体看[博客](https://www.cnblogs.com/tijun/p/7561718.html)

## 启动Spark

要启动Spark首先得启动Hadoop

### 启动Hadoop

先去hadoop目录下的bin目录，执行命令

```
./hadoop namenode -format
```

然后去sbin目录下执行./start-all.sh

### 启动Spark

也在sbin目录下面执行./start-all.sh

若在server1下执行jps命令能看到Master，则成功。
在其他机器上能看到Worker，则成功。


## 常见错误排除方法

1. 看log文件
2. 看配置文件有没有出错
3. 看是否配置选择太低